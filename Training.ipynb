{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d2854-332f-4930-8a0b-0e2c0ee51090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    LoadImage,\n",
    "    RandAffined,\n",
    "    PadListDataCollate,\n",
    "    RandSpatialCropd,\n",
    "    SpatialPadd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    RandRotate90d,\n",
    "    NormalizeIntensityd\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8960a-ce06-450a-b730-e010e644cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "num_workers = 4 if cuda else 0\n",
    "\n",
    "print('You are using gpu if true, cpu if false:', cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44381340-7372-4e3c-905d-03da8bb75c90",
   "metadata": {},
   "source": [
    "Need to set data directory to folders labeled with training images, validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a145e0f-7518-41bd-91e0-aeb1ed7e3c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir = ''\n",
    "\n",
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"images\", \"*.nii\")))\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labels\", \"*.nii\")))\n",
    "train_files = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "\n",
    "val_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"images_val\", \"*.nii\")))\n",
    "val_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"labels_val\", \"*.nii\")))\n",
    "val_files = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(val_images, val_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f312a06-716a-4b21-9bb8-f498a0ff1f14",
   "metadata": {},
   "source": [
    "Set up transforms used for training data loader. Depending on GPU availability, change \"roi\" variable to larger size to optimize the size of data. Z-dimension must be factorial of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2b37a-791f-4d7c-85d1-314f013e5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roi = [256,256,32]\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        SpatialPadd(keys=[\"image\", \"label\"],\n",
    "                  spatial_size=(512,512,416)),\n",
    "\n",
    "        RandSpatialCropd(keys=['image', 'label'],\n",
    "                         roi_size=(roi[0],roi[1],roi[2]),\n",
    "                         random_size=False),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.30,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.30,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.20,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419230db-f797-46ea-8bd0-70a6feb958e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=2,shuffle=True, num_workers=0)\n",
    "\n",
    "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbdfc26-ff8f-4044-8e97-d05fa669ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model used, Residual U-net\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764e360-ec68-4c4f-93b8-814ddd008451",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_NAME = #Name .pt folder to save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9875d-f33b-4fa1-a233-df28fd215b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 600\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "        \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                roi_size = (160, 160, 160)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(\n",
    "                    val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
    "                )\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save({\n",
    "                      'model_state_dict': model.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer.state_dict(),\n",
    "          }, PATH_NAME)\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "    if (epoch + 1) %20 == 0:\n",
    "        torch.save({\n",
    "                      'model_state_dict': model.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer.state_dict(),\n",
    "          }, data_dir + 'epoch'+str(epoch)+ '.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394cd8e-f1f2-4068-8e45-e2811a22176f",
   "metadata": {},
   "source": [
    "See final results on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af06d52-f7e3-4c98-bc32-2c62b18e841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "train_eval = Dataset(data=train_files, transform=val_transforms)\n",
    "train_eval_loader = DataLoader(train_eval, batch_size=1,num_workers=0)\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        model.eval()\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        val_outputs = sliding_window_inference(\n",
    "            val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
    "        )\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(val_data[\"image\"][0, 0, :, :, val_data['image'].shape[4]//2-10], cmap=\"gray\") # arbitrary slice selected for Z-dimension, can change\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(val_data[\"label\"][0, 0, :, :, val_data['image'].shape[4]//2-10])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(torch.argmax(\n",
    "            val_outputs, dim=1).detach().cpu()[0, :, :, val_data['image'].shape[4]//2-10])\n",
    "        plt.show()\n",
    "        if i == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f9b58-6f44-45b2-9581-3ca7f0750e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
